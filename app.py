import streamlit as st
import openai


# `__models` is a list of different models available in OpenAI's GPT-3 API. These models have
# different capabilities and performance levels. The list is used in the Streamlit app to allow the
# user to select a specific model to use for generating text.
__models  = [
                "gpt-3.5-turbo"
                ,"gpt-3.5-turbo-0301"
                ,"gpt-3.5-turbo-0613"
                ,"gpt-3.5-turbo-16k"
                ,"gpt-3.5-turbo-16k-0613"
            ]

# Functions
def get_completion(prompt, model="gpt-3.5-turbo-16k", temperature=0):
    """
    This function uses OpenAI's chat completion API to generate a response to a given prompt using a
    specified model and temperature.
    
    :param prompt: The text prompt or message that you want to send to the OpenAI chatbot for completion
    :param model: The name of the OpenAI language model being used for text generation. In this case, it
    is set to "gpt-3.5-turbo-16k", defaults to gpt-3.5-turbo-16k (optional)
    :param temperature: The temperature parameter controls the degree of randomness or creativity in the
    model's output. A higher temperature value will result in more diverse and unexpected responses,
    while a lower temperature value will result in more conservative and predictable responses. The
    default value is 0, which means the model will always output the most likely, defaults to 0
    (optional)
    :return: The function `get_completion` returns a string, which is the response generated by the
    OpenAI chatbot model based on the given prompt.
    """
    messages = [{"role": "user", "content": prompt}]
    response = openai.ChatCompletion.create(
        model=model,
        messages=messages,
        temperature=temperature, # this is the degree of randomness of the model's output
    )
    return response.choices[0].message["content"]

st.header("SQL assistant ðŸ¤–")
st.write("SQL powered with GPT")