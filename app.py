import streamlit as st
import openai
import os
from dotenv import load_dotenv, find_dotenv
_ = load_dotenv(find_dotenv()) # read local .env file

# You can use other name defined in the .env file
key_name = 'OPENAI_API_KEY'
openai.api_key  = os.getenv(key_name)

# Prompts
_input_text = None

def promp_table_to_datatable_type(input_text):
    return f"""
                        Based in the temporal table in SQL create a script to create a custom datatype table,
                        in the generated code add comments in english, 
                        the datatype name its the same as the temporal table,
                        and only return the TQSL code.

                        temporal table: '''{input_text}'''
                        """

# Functions
def get_completion(prompt, model="gpt-3.5-turbo-16k", temperature=0):
    """
    This function uses OpenAI's chat completion API to generate a response to a given prompt using a
    specified model and temperature.
    
    :param prompt: The text prompt or message that you want to send to the OpenAI chatbot for completion
    :param model: The name of the OpenAI language model being used for text generation. In this case, it
    is set to "gpt-3.5-turbo-16k", defaults to gpt-3.5-turbo-16k (optional)
    :param temperature: The temperature parameter controls the degree of randomness or creativity in the
    model's output. A higher temperature value will result in more diverse and unexpected responses,
    while a lower temperature value will result in more conservative and predictable responses. The
    default value is 0, which means the model will always output the most likely, defaults to 0
    (optional)
    :return: The function `get_completion` returns a string, which is the response generated by the
    OpenAI chatbot model based on the given prompt.
    """
    messages = [{"role": "user", "content": prompt}]
    response = openai.ChatCompletion.create(
        model=model,
        messages=messages,
        temperature=temperature, # this is the degree of randomness of the model's output
    )
    return response.choices[0].message["content"]

def check_openai(key,model="gpt-3.5-turbo-16k",max_tokens=5, temperature=0):
    """
    The function checks if an OpenAI API key is valid by attempting to create a completion with
    specified parameters.
    
    :param key: The OpenAI API key that is required to access the OpenAI API
    :param model: The OpenAI language model to use for text generation. In this case, the default model
    is "gpt-3.5-turbo-16k", defaults to gpt-3.5-turbo-16k (optional)
    :param max_tokens: The maximum number of tokens (words or symbols) that the OpenAI API will generate
    in response to a prompt, defaults to 5 (optional)
    :param temperature: Temperature is a parameter used in OpenAI's language models to control the
    creativity and randomness of the generated text. It determines how much the model should deviate
    from the most likely next word when generating text. A higher temperature value will result in more
    creative and diverse output, while a lower temperature value will, defaults to 0 (optional)
    :return: a boolean value. If the OpenAI API key is valid and the API call is successful, it will
    return True. If there is an error with the API call, it will return False and display the error
    message in the sidebar.
    """
    openai.api_key = key
    test_messages = [{"role": "user", "content": "Test"}]
    try:
        openai.ChatCompletion.create(
            model=model,
            messages=test_messages,
            max_tokens=max_tokens,
            temperature=temperature,
        )
        return True
    except Exception as e:
        return False

st.header("Temporal table to datatype")
st.divider()
_input_text = st.text_area('Write The temporal table code : ', '')

if st.button('Generate script'):
    st.divider()
    try:
        with st.spinner('Wait for it...'):
            response = get_completion(promp_table_to_datatable_type(_input_text), temperature=0)
            
        st.success('Done!')
        st.write(response)
        # Display the code using st.markdown
        st.markdown("```SQL\n{}\n```".format(response))
    except Exception as e:
        st.error(f'This is an error : {e}', icon="ðŸš¨")
